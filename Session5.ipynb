{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Session 5.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shubhamk16/NLP_END_Program/blob/main/Session5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jofyc9OC4Qcf"
      },
      "source": [
        "#Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahBVnrNc3E0U"
      },
      "source": [
        "import numpy as np\n",
        "%matplotlib inline\n",
        "import math\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython import display\n",
        "plt.style.use('seaborn-white')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crQSAaIz4SkA"
      },
      "source": [
        "# Read and process data. \n",
        "\n",
        "Download the file from this URL: https://drive.google.com/file/d/1UWWIi-sz9g0x3LFvkIZjvK1r2ZaCqgGS/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgOGxPDP3Wpp"
      },
      "source": [
        "data = open('text.txt', 'r').read()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZeXXMLRb4kXb"
      },
      "source": [
        "Process data and calculate indices"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E5TKeiOp4jtl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e7d17a6-cb11-4d5f-c143-1a8babe6ed48"
      },
      "source": [
        "chars = list(set(data))\n",
        "data_size, X_size = len(data), len(chars)\n",
        "print(\"Corona Virus article has %d characters, %d unique characters\" %(data_size, X_size))\n",
        "char_to_idx = {ch:i for i,ch in enumerate(chars)}\n",
        "idx_to_char = {i:ch for i,ch in enumerate(chars)}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Corona Virus article has 10223 characters, 75 unique characters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4C53MB135LRY"
      },
      "source": [
        "# Constants and Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfj21ORa49Ps"
      },
      "source": [
        "Hidden_Layer_size = 100 #size of the hidden layer\n",
        "Time_steps = 40 # Number of time steps (length of the sequence) used for training\n",
        "learning_rate = 1e-1 # Learning Rate\n",
        "weight_sd = 0.1 #Standard deviation of weights for initialization\n",
        "z_size = Hidden_Layer_size + X_size #Size of concatenation(H, X) vector"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdmJf4Du5uhb"
      },
      "source": [
        "# Activation Functions and Derivatives"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seGHei_D5FGk"
      },
      "source": [
        "def sigmoid(x): # sigmoid function\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def dsigmoid(y): # derivative of sigmoid function\n",
        "  return y * (1-y)\n",
        "\n",
        "def tanh(x): # tanh function\n",
        "  # Formula from: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Math/tanh\n",
        "  return np.tanh(x)\n",
        "  # return (np.exp(2*x) - 1)/(np.exp(2*x) + 1)\n",
        "\n",
        "def dtanh(y): # derivative of tanh\n",
        "  return 1 - y * y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeCvVH1v6Me-"
      },
      "source": [
        "# Quiz Question 1\n",
        "\n",
        "What is the value of sigmoid(0) calculated from  your code? (Answer up to 1 decimal point, e.g. 4.2 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 2\n",
        "\n",
        "What is the value of dsigmoid(sigmoid(0)) calculated from your code?? (Answer up to 2 decimal point, e.g. 4.29 and NOT 4.29999999, no rounding off). \n",
        "\n",
        "# Quiz Question 3\n",
        "\n",
        "What is the value of tanh(dsigmoid(sigmoid(0))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off).\n",
        "\n",
        "# Quiz Question 4\n",
        "\n",
        "What is the value of dtanh(tanh(dsigmoid(sigmoid(0)))) calculated from your code?? (Answer up to 5 decimal point, e.g. 4.29999 and NOT 4.29999999, no rounding off)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yh8-tzpw1yUK",
        "outputId": "c420c49e-0126-4b0e-df80-097274337c28"
      },
      "source": [
        "sigmoid(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uk4f1rY1ylu",
        "outputId": "3595e7f2-18f3-46cd-bfef-ebeae4840cde"
      },
      "source": [
        "dsigmoid(sigmoid(0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.25"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weWimxVb13C3",
        "outputId": "cc96c5be-4189-42fd-87ed-7b9c1dc7be93"
      },
      "source": [
        "tanh(dsigmoid(sigmoid(0)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.24491866240370913"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAizJaOI14S1",
        "outputId": "4f36fcda-3be8-4895-8609-5ee3a3ef5a84"
      },
      "source": [
        "dtanh(tanh(dsigmoid(sigmoid(0))))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.940014848806378"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeSVipDu8iKE"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICbWNemE6LGV"
      },
      "source": [
        "class Param:\n",
        "    def __init__(self, name, value):\n",
        "      self.name = name\n",
        "      self.v = value # parameter value\n",
        "      self.d = np.zeros_like(value) # derivative\n",
        "      self.m = np.zeros_like(value) # momentum for Adagrad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j83pZNPE8212"
      },
      "source": [
        "We use random weights with normal distribution (0, weight_sd) for  tanh  activation function and (0.5, weight_sd) for  `sigmoid`  activation function.\n",
        "\n",
        "Biases are initialized to zeros."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swHwLXOI9E7V"
      },
      "source": [
        "# LSTM \n",
        "You are making this network, please note f, i, c and o (also \"v\") in the image below:\n",
        "![alt text](http://blog.varunajayasiri.com/ml/lstm.svg)\n",
        "\n",
        "Please note that we are concatenating the old_hidden_vector and new_input."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0DBzNY-90s5"
      },
      "source": [
        "# Quiz Question 4\n",
        "\n",
        "In the class definition below, what should be size_a, size_b, and size_c? ONLY use the variables defined above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SFuHhqVq6Wge"
      },
      "source": [
        "size_a = Hidden_Layer_size\n",
        "size_b = z_size\n",
        "size_c = X_size\n",
        "\n",
        "class Parameters:\n",
        "    def __init__(self):\n",
        "        self.W_f = Param('W_f', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_f = Param('b_f', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_i = Param('W_i', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_i = Param('b_i', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_C = Param('W_C', np.random.randn(size_a, size_b) * weight_sd)\n",
        "        self.b_C = Param('b_C', np.zeros((size_a, 1)))\n",
        "\n",
        "        self.W_o = Param('W_o', np.random.randn(size_a, size_b) * weight_sd + 0.5)\n",
        "        self.b_o = Param('b_o', np.zeros((size_a, 1)))\n",
        "\n",
        "        #For final layer to predict the next character\n",
        "        self.W_v = Param('W_v', np.random.randn(X_size, size_a) * weight_sd)\n",
        "        self.b_v = Param('b_v', np.zeros((size_c, 1)))\n",
        "        \n",
        "    def all(self):\n",
        "        return [self.W_f, self.W_i, self.W_C, self.W_o, self.W_v,\n",
        "               self.b_f, self.b_i, self.b_C, self.b_o, self.b_v]\n",
        "        \n",
        "parameters = Parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzmfGLZt_xVs"
      },
      "source": [
        "Look at these operations which we'll be writing:\n",
        "\n",
        "**Concatenation of h and x:**\n",
        "\n",
        "$z\\:=\\:\\left[h_{t-1},\\:x\\right]$\n",
        "\n",
        "$f_t=\\sigma\\left(W_f\\cdot z\\:+\\:b_f\\:\\right)$\n",
        "\n",
        "$i_i=\\sigma\\left(W_i\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$\\overline{C_t}=\\tanh\\left(W_C\\cdot z\\:+\\:b_C\\right)$\n",
        "\n",
        "$C_t=f_t\\ast C_{t-1}+i_t\\ast \\overline{C}_t$\n",
        "\n",
        "$o_t=\\sigma\\left(W_o\\cdot z\\:+\\:b_i\\right)$\n",
        "\n",
        "$h_t=o_t\\ast\\tanh\\left(C_t\\right)$\n",
        "\n",
        "**Logits:**\n",
        "\n",
        "$v_t=W_v\\cdot h_t+b_v$\n",
        "\n",
        "**Softmax:**\n",
        "\n",
        "$\\hat{y}=softmax\\left(v_t\\right)$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bUkseNnDott"
      },
      "source": [
        "def forward(x, h_prev, C_prev, p = parameters):\n",
        "    assert x.shape == (X_size, 1)\n",
        "    assert h_prev.shape == (Hidden_Layer_size, 1)\n",
        "    assert C_prev.shape == (Hidden_Layer_size, 1)\n",
        "    \n",
        "    z = np.row_stack((h_prev, x))\n",
        "    f = sigmoid(np.dot(p.W_f.v, z) + p.b_f.v)\n",
        "    i = sigmoid(np.dot(p.W_i.v, z) + p.b_i.v)\n",
        "    C_bar = tanh(np.dot(p.W_C.v, z) + p.b_C.v)\n",
        "\n",
        "    C = f * C_prev + i * C_bar\n",
        "    o = sigmoid(np.dot(p.W_o.v, z) + p.b_o.v)\n",
        "    h = o * tanh(C)\n",
        "\n",
        "    v = np.dot(p.W_v.v, h) + p.b_v.v\n",
        "    y = np.exp(v) / np.sum(np.exp(v)) #softmax\n",
        "\n",
        "    return z, f, i, C_bar, C, o, h, v, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZrDhZIjFpdI"
      },
      "source": [
        "You must finish the function above before you can attempt the questions below. \n",
        "\n",
        "# Quiz Question 5\n",
        "\n",
        "What is the output of 'print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))'?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7i0wfdu__45P",
        "outputId": "a9756d1e-c774-4568-afdd-bf88da2c343f"
      },
      "source": [
        "print(len(forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)), parameters)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XV-YVl_GGiX8"
      },
      "source": [
        "# Quiz Question 6. \n",
        "\n",
        "Assuming you have fixed the forward function, run this command: \n",
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))\n",
        "\n",
        "Now, find these values:\n",
        "\n",
        "\n",
        "1.   print(z.shape)\n",
        "2.   print(np.sum(z))\n",
        "3.   print(np.sum(f))\n",
        "\n",
        "Copy and paste exact values you get in the logs into the quiz.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GvKVWmTDt3H"
      },
      "source": [
        "z, f, i, C_bar, C, o, h, v, y = forward(np.zeros((X_size, 1)), np.zeros((Hidden_Layer_size, 1)), np.zeros((Hidden_Layer_size, 1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FyQfM42UA6Bv",
        "outputId": "597119ed-c07d-4b38-ae12-9e1183518ec3"
      },
      "source": [
        "print(z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(175, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmx9JGgzA7Ha",
        "outputId": "340adb50-a370-478d-944f-3028d294accf"
      },
      "source": [
        "print(np.sum(z))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6tIAlGfA8IN",
        "outputId": "f0d21485-8c96-4b4c-86d6-0d6a2725764b"
      },
      "source": [
        "print(np.sum(f))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeSvhkqwILsG"
      },
      "source": [
        "# Backpropagation\n",
        "\n",
        "Here we are defining the backpropagation. It's too complicated, here is the whole code. (Please note that this would work only if your earlier code is perfect)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zIa1jUZiGPmF"
      },
      "source": [
        "def backward(target, dh_next, dC_next, C_prev,\n",
        "             z, f, i, C_bar, C, o, h, v, y,\n",
        "             p = parameters):\n",
        "    \n",
        "    assert z.shape == (X_size + Hidden_Layer_size, 1)\n",
        "    assert v.shape == (X_size, 1)\n",
        "    assert y.shape == (X_size, 1)\n",
        "    \n",
        "    for param in [dh_next, dC_next, C_prev, f, i, C_bar, C, o, h]:\n",
        "        assert param.shape == (Hidden_Layer_size, 1)\n",
        "        \n",
        "    dv = np.copy(y)\n",
        "    dv[target] -= 1\n",
        "\n",
        "    p.W_v.d += np.dot(dv, h.T)\n",
        "    p.b_v.d += dv\n",
        "\n",
        "    dh = np.dot(p.W_v.v.T, dv)        \n",
        "    dh += dh_next\n",
        "    do = dh * tanh(C)\n",
        "    do = dsigmoid(o) * do\n",
        "    p.W_o.d += np.dot(do, z.T)\n",
        "    p.b_o.d += do\n",
        "\n",
        "    dC = np.copy(dC_next)\n",
        "    dC += dh * o * dtanh(tanh(C))\n",
        "    dC_bar = dC * i\n",
        "    dC_bar = dtanh(C_bar) * dC_bar\n",
        "    p.W_C.d += np.dot(dC_bar, z.T)\n",
        "    p.b_C.d += dC_bar\n",
        "\n",
        "    di = dC * C_bar\n",
        "    di = dsigmoid(i) * di\n",
        "    p.W_i.d += np.dot(di, z.T)\n",
        "    p.b_i.d += di\n",
        "\n",
        "    df = dC * C_prev\n",
        "    df = dsigmoid(f) * df\n",
        "    p.W_f.d += np.dot(df, z.T)\n",
        "    p.b_f.d += df\n",
        "\n",
        "    dz = (np.dot(p.W_f.v.T, df)\n",
        "         + np.dot(p.W_i.v.T, di)\n",
        "         + np.dot(p.W_C.v.T, dC_bar)\n",
        "         + np.dot(p.W_o.v.T, do))\n",
        "    dh_prev = dz[:Hidden_Layer_size, :]\n",
        "    dC_prev = f * dC\n",
        "    \n",
        "    return dh_prev, dC_prev"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tnc7WpRkIU5S"
      },
      "source": [
        "# Forward and Backward Combined Pass\n",
        "\n",
        "Let's first clear the gradients before each backward pass"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJWoC3U1ITf8"
      },
      "source": [
        "def clear_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.d.fill(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7XN93UnjIgmA"
      },
      "source": [
        "Clip gradients to mitigate exploding gradients"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LTsublxIfFl"
      },
      "source": [
        "def clip_gradients(params = parameters):\n",
        "    for p in params.all():\n",
        "        np.clip(p.d, -1, 1, out=p.d)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7XUpDTWIl_Y"
      },
      "source": [
        "Calculate and store the values in forward pass. Accumulate gradients in backward pass and clip gradients to avoid exploding gradients.\n",
        "\n",
        "input, target are list of integers, with character indexes.\n",
        "h_prev is the array of initial h at  h−1  (size H x 1)\n",
        "C_prev is the array of initial C at  C−1  (size H x 1)\n",
        "Returns loss, final  hT  and  CT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQNxjTuZIia_"
      },
      "source": [
        "def forward_backward(inputs, targets, h_prev, C_prev):\n",
        "    global paramters\n",
        "    \n",
        "    # To store the values for each time step\n",
        "    x_s, z_s, f_s, i_s,  = {}, {}, {}, {}\n",
        "    C_bar_s, C_s, o_s, h_s = {}, {}, {}, {}\n",
        "    v_s, y_s =  {}, {}\n",
        "    \n",
        "    # Values at t - 1\n",
        "    h_s[-1] = np.copy(h_prev)\n",
        "    C_s[-1] = np.copy(C_prev)\n",
        "    \n",
        "    loss = 0\n",
        "    # Loop through time steps\n",
        "    assert len(inputs) == Time_steps\n",
        "    for t in range(len(inputs)):\n",
        "        x_s[t] = np.zeros((X_size, 1))\n",
        "        x_s[t][inputs[t]] = 1 # Input character\n",
        "        \n",
        "        (z_s[t], f_s[t], i_s[t],\n",
        "        C_bar_s[t], C_s[t], o_s[t], h_s[t],\n",
        "        v_s[t], y_s[t]) = \\\n",
        "            forward(x_s[t], h_s[t - 1], C_s[t - 1]) # Forward pass\n",
        "            \n",
        "        loss += -np.log(y_s[t][targets[t], 0]) # Loss for at t\n",
        "        \n",
        "    clear_gradients()\n",
        "\n",
        "    dh_next = np.zeros_like(h_s[0]) #dh from the next character\n",
        "    dC_next = np.zeros_like(C_s[0]) #dh from the next character\n",
        "\n",
        "    for t in reversed(range(len(inputs))):\n",
        "        # Backward pass\n",
        "        dh_next, dC_next = \\\n",
        "            backward(target = targets[t], dh_next = dh_next,\n",
        "                     dC_next = dC_next, C_prev = C_s[t-1],\n",
        "                     z = z_s[t], f = f_s[t], i = i_s[t], C_bar = C_bar_s[t],\n",
        "                     C = C_s[t], o = o_s[t], h = h_s[t], v = v_s[t],\n",
        "                     y = y_s[t])\n",
        "\n",
        "    clip_gradients()\n",
        "        \n",
        "    return loss, h_s[len(inputs) - 1], C_s[len(inputs) - 1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcy5u_vRItkV"
      },
      "source": [
        "# Sample the next character"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8SrtJiwIsSm"
      },
      "source": [
        "def sample(h_prev, C_prev, first_char_idx, sentence_length):\n",
        "    x = np.zeros((X_size, 1))\n",
        "    x[first_char_idx] = 1\n",
        "\n",
        "    h = h_prev\n",
        "    C = C_prev\n",
        "\n",
        "    indexes = []\n",
        "    \n",
        "    for t in range(sentence_length):\n",
        "        _, _, _, _, C, _, h, _, p = forward(x, h, C)\n",
        "        idx = np.random.choice(range(X_size), p=p.ravel())\n",
        "        x = np.zeros((X_size, 1))\n",
        "        x[idx] = 1\n",
        "        indexes.append(idx)\n",
        "\n",
        "    return indexes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SiWFaWLNIx_L"
      },
      "source": [
        "# Training (Adagrad)\n",
        "\n",
        "Update the graph and display a sample output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENQYU-7AIw0t"
      },
      "source": [
        "def update_status(inputs, h_prev, C_prev):\n",
        "    #initialized later\n",
        "    global plot_iter, plot_loss\n",
        "    global smooth_loss\n",
        "    \n",
        "    # Get predictions for 200 letters with current model\n",
        "\n",
        "    sample_idx = sample(h_prev, C_prev, inputs[0], 200)\n",
        "    txt = ''.join(idx_to_char[idx] for idx in sample_idx)\n",
        "\n",
        "    # Clear and plot\n",
        "    plt.plot(plot_iter, plot_loss)\n",
        "    display.clear_output(wait=True)\n",
        "    plt.show()\n",
        "\n",
        "    #Print prediction and loss\n",
        "    print(\"----\\n %s \\n----\" % (txt, ))\n",
        "    print(\"iter %d, loss %f\" % (iteration, smooth_loss))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACXcASJuI73a"
      },
      "source": [
        "# Update Parameters\n",
        "\n",
        "\\begin{align}\n",
        "\\theta_i &= \\theta_i - \\eta\\frac{d\\theta_i}{\\sum dw_{\\tau}^2} \\\\\n",
        "d\\theta_i &= \\frac{\\partial L}{\\partial \\theta_i}\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bR08TvcjI4Pf"
      },
      "source": [
        "def update_paramters(params = parameters):\n",
        "    for p in params.all():\n",
        "        p.m += p.d * p.d # Calculate sum of gradients\n",
        "        #print(learning_rate * dparam)\n",
        "        p.v += -(learning_rate * p.d / np.sqrt(p.m + 1e-8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "La9vyJ6RJLFK"
      },
      "source": [
        "To delay the keyboard interrupt to prevent the training from stopping in the middle of an iteration\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVDHbMb7JNGT"
      },
      "source": [
        "# Exponential average of loss\n",
        "# Initialize to a error of a random model\n",
        "smooth_loss = -np.log(1.0 / X_size) * Time_steps\n",
        "\n",
        "iteration, pointer = 0, 0\n",
        "\n",
        "# For the graph\n",
        "plot_iter = np.zeros((0))\n",
        "plot_loss = np.zeros((0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HF6vS0VWJqsS"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OQyNSL0iJOxH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "outputId": "af72abdd-e347-4421-fa62-7691d2dbb451"
      },
      "source": [
        "iter = 50_000\n",
        "while iter > 0:\n",
        "  # Reset\n",
        "  if pointer + Time_steps >= len(data) or iteration == 0:\n",
        "      g_h_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      g_C_prev = np.zeros((Hidden_Layer_size, 1))\n",
        "      pointer = 0\n",
        "\n",
        "\n",
        "  inputs = ([char_to_idx[ch] \n",
        "              for ch in data[pointer: pointer + Time_steps]])\n",
        "  targets = ([char_to_idx[ch] \n",
        "              for ch in data[pointer + 1: pointer + Time_steps + 1]])\n",
        "\n",
        "  loss, g_h_prev, g_C_prev = \\\n",
        "      forward_backward(inputs, targets, g_h_prev, g_C_prev)\n",
        "  smooth_loss = smooth_loss * 0.999 + loss * 0.001\n",
        "\n",
        "  # Print every hundred steps\n",
        "  if iteration % 1000 == 0:\n",
        "      update_status(inputs, g_h_prev, g_C_prev)\n",
        "\n",
        "  update_paramters()\n",
        "\n",
        "  plot_iter = np.append(plot_iter, [iteration])\n",
        "  plot_loss = np.append(plot_loss, [loss])\n",
        "\n",
        "  pointer += Time_steps\n",
        "  iteration += 1\n",
        "  iter = iter -1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "----\n",
            " the furvermentiver traveleds a feriching or potifer source to see the acaces sealth ialty was hopring to seeptone gets hovel 30s travel repirlally\n",
            "\n",
            "Alit if cases for from out in youg Coronavirus inclu \n",
            "----\n",
            "iter 49000, loss 7.036876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AKpa1BGOItQ"
      },
      "source": [
        "# Quiz Question 7. \n",
        "\n",
        "Run the above code for 50000 iterations making sure that you have 100 hidden layers and time_steps is 40. What is the loss value you're seeing?\n",
        "\n",
        "125.503104"
      ]
    }
  ]
}